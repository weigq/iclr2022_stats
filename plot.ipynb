{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131805a1",
   "metadata": {
    "id": "131805a1"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from tqdm import trange\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "gridc = (1., 1., 1)\n",
    "plt.rcParams['grid.color'] = gridc\n",
    "plt.rcParams[\"axes.edgecolor\"] = (0.898, 0.925, 0.965, 1)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "\n",
    "from database import DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b328575",
   "metadata": {
    "id": "5b328575"
   },
   "outputs": [],
   "source": [
    "db = DataBase('assets/iclr2022.db')\n",
    "db.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02d46bb",
   "metadata": {
    "id": "a02d46bb"
   },
   "source": [
    "### key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7661c",
   "metadata": {
    "id": "b7d7661c"
   },
   "outputs": [],
   "source": [
    "# all submissions \n",
    "_cmd = \"SELECT keywords FROM submissions;\"\n",
    "db.cursor.execute(_cmd)\n",
    "data = db.cursor.fetchall()\n",
    "keywords = {}\n",
    "for i in trange(len(data)):\n",
    "    _kw = data[i][0].split(', ')\n",
    "    _kw = [_k.lower().strip() for _k in _kw]\n",
    "    for _k in _kw:\n",
    "        if _k in keywords.keys():\n",
    "            keywords[_k] += 1\n",
    "        else:\n",
    "            keywords[_k] = 1\n",
    "# sort values\n",
    "keywords = {k: v for k, v in sorted(keywords.items(), key=lambda item: item[1])[::-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcf1f2a",
   "metadata": {
    "id": "7fcf1f2a"
   },
   "outputs": [],
   "source": [
    "# merge some redundant keywords\n",
    "clear_keywords = keywords.copy()\n",
    "# transformer\n",
    "clear_keywords.update({'transformer(s)': 0})\n",
    "pops = []\n",
    "for k, v in clear_keywords.items():\n",
    "    if 'transformer' in k and k != 'transformer(s)':\n",
    "        clear_keywords['transformer(s)'] += v\n",
    "        pops.append(k)\n",
    "# graph NN\n",
    "clear_keywords.update({'graph neural network(s)': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'graph neural network' in k and k != 'graph neural network(s)':\n",
    "        clear_keywords['graph neural network(s)'] += v\n",
    "        pops.append(k)\n",
    "# RL\n",
    "clear_keywords.update({'(deep) reinforcement learning': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'reinforcement learning' in k and k != '(deep) reinforcement learning':\n",
    "        clear_keywords['(deep) reinforcement learning'] += v\n",
    "        pops.append(k)\n",
    "# generative model\n",
    "clear_keywords.update({'generative model(s)': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'generative model' in k and k != 'generative model(s)':\n",
    "        clear_keywords['generative model(s)'] += v\n",
    "        pops.append(k)\n",
    "# representation learning\n",
    "clear_keywords.update({'representation learning(s)': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'representation learning' in k and k != 'representation learning(s)':\n",
    "        clear_keywords['representation learning(s)'] += v\n",
    "        pops.append(k)\n",
    "# self-supervised\n",
    "clear_keywords.update({'self-supervised(s)': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'self-supervised' in k and k != 'self-supervised(s)':\n",
    "        clear_keywords['self-supervised(s)'] += v\n",
    "        pops.append(k)\n",
    "# unsupervised\n",
    "clear_keywords.update({'unsupervised(s)': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'unsupervised' in k and k != 'unsupervised(s)':\n",
    "        clear_keywords['unsupervised(s)'] += v\n",
    "        pops.append(k)\n",
    "# contrastive learning\n",
    "clear_keywords.update({'contrastive learning(s)': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'contrastive learning' in k and k != 'contrastive learning(s)':\n",
    "        clear_keywords['contrastive learning(s)'] += v\n",
    "        pops.append(k)\n",
    "# deep learning\n",
    "clear_keywords.update({'deep learning(s)': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'deep learning' in k and k != 'deep learning(s)':\n",
    "        clear_keywords['deep learning(s)'] += v\n",
    "        pops.append(k)\n",
    "# optimization\n",
    "clear_keywords.update({'optimization(s)': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'optimization' in k and k != 'optimization(s)':\n",
    "        clear_keywords['optimization(s)'] += v\n",
    "        pops.append(k)\n",
    "# adversaial robustness\n",
    "clear_keywords.update({'(adversaial) robustness': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'robustness' in k and k != '(adversaial) robustness':\n",
    "        clear_keywords['(adversaial) robustness'] += v\n",
    "        pops.append(k)\n",
    "# attention\n",
    "clear_keywords.update({'attention(s)': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'attention' in k and k != 'attention(s)':\n",
    "        clear_keywords['attention(s)'] += v\n",
    "        pops.append(k)\n",
    "# learning theory\n",
    "clear_keywords.update({'learning theory(-ies)': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'learning theory' in k and k != 'learning theory(-ies)':\n",
    "        clear_keywords['learning theory(-ies)'] += v\n",
    "        pops.append(k)\n",
    "# generalization\n",
    "clear_keywords.update({'generalization(s)': 0})\n",
    "for k, v in clear_keywords.items():\n",
    "    if 'generalization' in k and k != 'generalization(s)':\n",
    "        clear_keywords['generalization(s)'] += v\n",
    "        pops.append(k)\n",
    "# meta-learning\n",
    "clear_keywords.update({'meta-learning(s)': 0})\n",
    "for k, v in clear_keywords.items():\n",
    "    if ('meta-learning' in k or 'meta learning' in k) and k != 'meta-learning(s)':\n",
    "        clear_keywords['meta-learning(s)'] += v\n",
    "        pops.append(k)\n",
    "# online learning\n",
    "clear_keywords.update({'online learning(s)': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'online learning' in k and k != 'online learning(s)':\n",
    "        clear_keywords['online learning(s)'] += v\n",
    "        pops.append(k)\n",
    "# differential privacy\n",
    "clear_keywords.update({'differential privacy(-ies)': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'differential privacy' in k and k != 'differential privacy(-ies)':\n",
    "        clear_keywords['differential privacy(-ies)'] += v\n",
    "        pops.append(k)\n",
    "# computer vision\n",
    "clear_keywords.update({'computer vision(s)': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'computer vision' in k and k != 'computer vision(s)':\n",
    "        clear_keywords['computer vision(s)'] += v\n",
    "        pops.append(k)\n",
    "# neural networks\n",
    "clear_keywords.update({'neural network(s)': 0})\n",
    "for k, v in clear_keywords.items():\n",
    "    if ('neural network' in k and 'graph neural network' not in k) and k != 'neural network(s)':\n",
    "        clear_keywords['neural network(s)'] += v\n",
    "        pops.append(k)\n",
    "# transfer learning\n",
    "clear_keywords.update({'transfer learning(s)': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'transfer learning' in k and k != 'transfer learning(s)':\n",
    "        clear_keywords['transfer learning(s)'] += v\n",
    "        pops.append(k)\n",
    "# federated learning\n",
    "clear_keywords.update({'federated learning(s)': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'federated learning' in k and k != 'federated learning(s)':\n",
    "        clear_keywords['federated learning(s)'] += v\n",
    "        pops.append(k)\n",
    "# variational inference\n",
    "clear_keywords.update({'variational inference(s)': 0})\n",
    "for k, v in clear_keywords.items():\n",
    "    if 'variational inference' in k and k != 'variational inference(s)':\n",
    "        clear_keywords['variational inference(s)'] += v\n",
    "        pops.append(k)\n",
    "# 3d\n",
    "clear_keywords.update({'3d(s)': 0})\n",
    "for k, v in clear_keywords.items():\n",
    "    if '3d' in k and k != '3d(s)':\n",
    "        clear_keywords['3d(s)'] += v\n",
    "        pops.append(k)\n",
    "# language\n",
    "clear_keywords.update({'language(s)': 0})\n",
    "for k, v in clear_keywords.items():\n",
    "    if 'language' in k and k != 'language(s)':\n",
    "        clear_keywords['language(s)'] += v\n",
    "        pops.append(k)\n",
    "# machine learning\n",
    "clear_keywords.update({'machine learning(s)': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'machine learning' in k and k != 'machine learning(s)':\n",
    "        clear_keywords['machine learning(s)'] += v\n",
    "        pops.append(k)\n",
    "# few-shot learning\n",
    "clear_keywords.update({'few-shot learning(s)': 0})\n",
    "for k, v in keywords.items():\n",
    "    if 'few-shot learning' in k and k != 'few-shot learning(s)':\n",
    "        clear_keywords['few-shot learning(s)'] += v\n",
    "        pops.append(k)\n",
    "# domain adaptation(s)\n",
    "clear_keywords.update({'domain adaptation(s)': 0})\n",
    "for k, v in clear_keywords.items():\n",
    "    if 'domain adaptation' in k and k != 'domain adaptation(s)':\n",
    "        clear_keywords['domain adaptation(s)'] += v\n",
    "        pops.append(k)\n",
    "# fairness\n",
    "clear_keywords.update({'fairness(s)': 0})\n",
    "for k, v in clear_keywords.items():\n",
    "    if 'fairness' in k and k != 'fairness(s)':\n",
    "        clear_keywords['fairness(s)'] += v\n",
    "        pops.append(k)\n",
    "# interpretability\n",
    "clear_keywords.update({'interpretability(-ies)': 0})\n",
    "for k, v in clear_keywords.items():\n",
    "    if 'interpretability' in k and k != 'interpretability(-ies)':\n",
    "        clear_keywords['interpretability(-ies)'] += v\n",
    "        pops.append(k)\n",
    "# gaussian process\n",
    "clear_keywords.update({'gaussian process(s)': 0})\n",
    "for k, v in clear_keywords.items():\n",
    "    if 'gaussian process' in k and k != 'gaussian process(s)':\n",
    "        clear_keywords['gaussian process(s)'] += v\n",
    "        pops.append(k)\n",
    "for pop in set(pops):\n",
    "    print(pop)\n",
    "    clear_keywords.pop(pop)\n",
    "clear_keywords = {k: v for k, v in sorted(clear_keywords.items(), key=lambda item: item[1])[::-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jmdMkKwQhKDX",
   "metadata": {
    "id": "jmdMkKwQhKDX"
   },
   "outputs": [],
   "source": [
    "words = {}\n",
    "for keyword, cnt in keywords.items():\n",
    "  _words = keyword.split(' ')\n",
    "  for word in _words:\n",
    "    word = word[:-1] if word.endswith('s') else word\n",
    "    if word in ['learning', 'neural', 'network', 'optimization', 'model',\n",
    "               'theory', 'inference', 'method', 'algorithm', 'data', 'gradient',\n",
    "               'estimation', 'image', 'machine', 'analysi', 'of', 'system',\n",
    "               'dynamic', 'approximation', 'function']:\n",
    "      continue\n",
    "    if word not in words:\n",
    "      words[word] = 0\n",
    "    words[word] += cnt\n",
    "\n",
    "words = dict(sorted(words.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "clear_keywords = {}\n",
    "for word, cnt in words.items():\n",
    "  for keyword in keywords:\n",
    "    if word in keyword:\n",
    "      if keyword not in clear_keywords:\n",
    "        clear_keywords[keyword] = 0\n",
    "      clear_keywords[keyword] += cnt\n",
    "      break\n",
    "clear_keywords = dict(sorted(clear_keywords.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2189926b",
   "metadata": {
    "id": "2189926b"
   },
   "outputs": [],
   "source": [
    "# original keywords\n",
    "ttl = 40\n",
    "kws = list(keywords.keys())[:ttl]\n",
    "freqs = list(keywords.values())[:ttl]\n",
    "\n",
    "\n",
    "width = 0.5\n",
    "fig = plt.figure(figsize=[18, 6])\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_facecolor((0.898, 0.925, 0.965, 0.5))\n",
    "ax.spines['left'].set_color('w')\n",
    "ax.spines['bottom'].set_color('w')\n",
    "ax.spines['right'].set_color('w')\n",
    "ax.spines['top'].set_color('w')\n",
    "\n",
    "colors = ['#789BFF', '#FE8671'] * (ttl // 2)\n",
    "\n",
    "# all keywords\n",
    "ax.bar(np.arange(ttl), freqs, width=width, alpha=0.95, \n",
    "       color=colors, capsize=4)\n",
    "for i, v in zip(np.arange(ttl), freqs):\n",
    "    ax.text(i - 0.5 if v >= 100 else i - 0.3, v + 4.0, str(v), color=colors[i], fontsize=12)\n",
    "\n",
    "plt.ylim(0, 215)\n",
    "plt.xticks(ticks=np.arange(ttl), rotation=45,\n",
    "           labels=[d for d in kws], ha='right')\n",
    "for ticklabel, tickcolor in zip(plt.gca().get_xticklabels(), colors):\n",
    "    ticklabel.set_color(tickcolor)\n",
    "ax.set_ylabel(r\"#\", fontsize=14)\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid()\n",
    "plt.savefig('assets/keywords_bar.png', bbox_inches='tight', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd772820",
   "metadata": {
    "id": "cd772820"
   },
   "outputs": [],
   "source": [
    "# clear keywords\n",
    "ttl = 30\n",
    "kws = list(clear_keywords.keys())[:ttl]\n",
    "freqs = list(clear_keywords.values())[:ttl]\n",
    "\n",
    "\n",
    "width = 0.5\n",
    "fig = plt.figure(figsize=[16, 6])\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_facecolor((0.898, 0.925, 0.965, 0.5))\n",
    "ax.spines['left'].set_color('w')\n",
    "ax.spines['bottom'].set_color('w')\n",
    "ax.spines['right'].set_color('w')\n",
    "ax.spines['top'].set_color('w')\n",
    "\n",
    "colors = ['#789BFF', '#FE8671'] * (ttl // 2)\n",
    "\n",
    "# all keywords\n",
    "ax.bar(np.arange(ttl), freqs, width=width, alpha=0.95, \n",
    "       color=colors, capsize=4)\n",
    "for i, v in zip(np.arange(ttl), freqs):\n",
    "    ax.text(i - 0.25 if v >= 100 else i - 0.2, v + 4.0, str(v), color=colors[i], fontsize=12)\n",
    "\n",
    "plt.ylim(0, 400)\n",
    "plt.xticks(ticks=np.arange(ttl), rotation=45,\n",
    "           labels=[d for d in kws], ha='right')\n",
    "for ticklabel, tickcolor in zip(plt.gca().get_xticklabels(), colors):\n",
    "    ticklabel.set_color(tickcolor)\n",
    "ax.set_ylabel(r\"#\", fontsize=14)\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid()\n",
    "plt.savefig('assets/clear_keywords_bar.png', bbox_inches='tight', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd75c52",
   "metadata": {
    "id": "dcd75c52"
   },
   "source": [
    "### statistics bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d9b636",
   "metadata": {
    "id": "a0d9b636"
   },
   "outputs": [],
   "source": [
    "# all decisions\n",
    "_cmd = \"SELECT rating_avg FROM submissions;\"\n",
    "db.cursor.execute(_cmd)\n",
    "data = db.cursor.fetchall()\n",
    "rating_avgs = np.array(data)\n",
    "print(\"> Total submissions (including CE): {}\".format(len(data)))\n",
    "print(f\"    Average ratings: {rating_avgs.mean():.2f}\")\n",
    "print(f\"    Max ratings: {rating_avgs.max():.2f}\")\n",
    "print(f\"    Min ratings: {rating_avgs.min():.2f}\")\n",
    "\n",
    "# oral\n",
    "_cmd = \"SELECT rating_avg FROM submissions WHERE now_decision LIKE '%Oral%';\"\n",
    "db.cursor.execute(_cmd)\n",
    "data = db.cursor.fetchall()\n",
    "oral_avgs = np.array(data)\n",
    "print(\"> Oral submissions (including CE): {}\".format(oral_avgs.shape[0]))\n",
    "print(f\"    Average ratings: {oral_avgs.mean():.2f}\")\n",
    "print(f\"    Max ratings: {oral_avgs.max():.2f}\")\n",
    "print(f\"    Min ratings: {oral_avgs.min():.2f}\")\n",
    "\n",
    "# spotlight\n",
    "_cmd = \"SELECT rating_avg FROM submissions WHERE now_decision LIKE '%Spotlight%';\"\n",
    "db.cursor.execute(_cmd)\n",
    "data = db.cursor.fetchall()\n",
    "spotlight_avgs = np.array(data)\n",
    "print(\"> Soitlight submissions (including CE): {}\".format(spotlight_avgs.shape[0]))\n",
    "print(f\"    Average ratings: {spotlight_avgs.mean():.2f}\")\n",
    "print(f\"    Max ratings: {spotlight_avgs.max():.2f}\")\n",
    "print(f\"    Min ratings: {spotlight_avgs.min():.2f}\")\n",
    "\n",
    "# poster\n",
    "_cmd = \"SELECT rating_avg FROM submissions WHERE now_decision LIKE '%Poster%';\"\n",
    "db.cursor.execute(_cmd)\n",
    "data = db.cursor.fetchall()\n",
    "poster_avgs = np.array(data)\n",
    "print(\"> Poster submissions (including CE): {}\".format(poster_avgs.shape[0]))\n",
    "print(f\"    Average ratings: {poster_avgs.mean():.2f}\")\n",
    "print(f\"    Max ratings: {poster_avgs.max():.2f}\")\n",
    "print(f\"    Min ratings: {poster_avgs.min():.2f}\")\n",
    "\n",
    "# reject\n",
    "_cmd = \"SELECT rating_avg FROM submissions WHERE now_decision LIKE '%Reject%';\"\n",
    "db.cursor.execute(_cmd)\n",
    "data = db.cursor.fetchall()\n",
    "reject_avgs = np.array(data)\n",
    "print(\"> Reject submissions (including CE): {}\".format(reject_avgs.shape[0]))\n",
    "print(f\"    Average ratings: {reject_avgs.mean():.2f}\")\n",
    "print(f\"    Max ratings: {reject_avgs.max():.2f}\")\n",
    "print(f\"    Min ratings: {reject_avgs.min():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f9d3bb",
   "metadata": {
    "id": "09f9d3bb"
   },
   "outputs": [],
   "source": [
    "_min, _max = rating_avgs.min(), rating_avgs.max()\n",
    "\n",
    "width = 0.16\n",
    "fig = plt.figure(figsize=[16, 6])\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_facecolor((0.898, 0.925, 0.965, 0.5))\n",
    "ax.spines['left'].set_color('w')\n",
    "ax.spines['bottom'].set_color('w')\n",
    "ax.spines['right'].set_color('w')\n",
    "ax.spines['top'].set_color('w')\n",
    "\n",
    "# all submissions\n",
    "hist, bin_edges = np.histogram(rating_avgs, bins=20, range=(_min, _max))\n",
    "# ax.bar(np.linspace(_min, _max, len(hist)), hist, width=width, alpha=0.95, \n",
    "#        color='#789BFF', capsize=4)\n",
    "for i, v in zip(np.linspace(_min, _max, len(hist)), hist):\n",
    "    ax.text(i - 0.1 if v >= 100 else i - 0.05, v + 6.0, str(v), color='#1f59ff', fontsize=16)\n",
    "\n",
    "# reject\n",
    "hist_reject, _ = np.histogram(reject_avgs, bins=20, range=(_min, _max))\n",
    "ax.bar(np.linspace(_min, _max, len(hist)), hist_reject, width=width, alpha=0.95, \n",
    "       color='#E3E7FF', capsize=4, label='Reject')\n",
    "\n",
    "# poster\n",
    "hist_poster, _ = np.histogram(poster_avgs, bins=20, range=(_min, _max))\n",
    "ax.bar(np.linspace(_min, _max, len(hist)), hist_poster, bottom=hist_reject, width=width, alpha=0.95, \n",
    "       color='#A0B5FF', capsize=4, label='Poster')\n",
    "\n",
    "# spotlight\n",
    "hist_spotlight, _ = np.histogram(spotlight_avgs, bins=20, range=(_min, _max))\n",
    "ax.bar(np.linspace(_min, _max, len(hist)), hist_spotlight, bottom=hist_poster + hist_reject, \n",
    "       width=width, alpha=0.95, \n",
    "       color='#7879FF', capsize=4, label='Spotlight')\n",
    "\n",
    "# oral\n",
    "hist_oral, _ = np.histogram(oral_avgs, bins=20, range=(_min, _max))\n",
    "ax.bar(np.linspace(_min, _max, len(hist)), hist_oral, bottom=hist_poster + hist_reject + hist_spotlight, \n",
    "       width=width, alpha=0.95, \n",
    "       color='#FF435B', capsize=4, label='Oral')\n",
    "\n",
    "plt.ylim(0, 550)\n",
    "plt.xticks(ticks=np.linspace(_min, _max, len(hist)), \n",
    "           rotation=40, \n",
    "           labels=[f\"{d:.2f}\" for d in np.linspace(_min, _max, len(hist))])\n",
    "ax.set_ylabel(r\"# submissions\", fontsize=14)\n",
    "ax.set_xlabel(\"Rating\", fontsize=14)\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], loc=2, fontsize=14)\n",
    "plt.savefig('assets/stats_bar.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0011116b",
   "metadata": {
    "id": "0011116b"
   },
   "outputs": [],
   "source": [
    "# consistency experiment statistics\n",
    "_cmd = \"SELECT * FROM submissions WHERE num_decision == 2 ORDER BY title;\"\n",
    "db.cursor.execute(_cmd)\n",
    "data = db.cursor.fetchall()\n",
    "print(\"> Total submissions with CE: {}\".format(len(data) // 2))\n",
    "num_comflict = 0\n",
    "num_consist = 0\n",
    "ces = {}\n",
    "for i in range(0, len(data), 2):  \n",
    "    dcs = data[i][6].split(' ')[-1].strip('()')\n",
    "    dcs_0 = data[i][7].split(' ')[-1].strip('()')\n",
    "    dcs_1 = data[i + 1][7].split(' ')[-1].strip('()')  \n",
    "    _key = \", \".join(sorted([dcs_0, dcs_1]))\n",
    "    _key = dcs + ', ' + _key\n",
    "    if _key in ces.keys():\n",
    "        ces[_key] += 1\n",
    "    else:\n",
    "        ces.update({_key: 1})\n",
    "    assert data[i][2] == data[i + 1][2], f'not match for {i}'\n",
    "    if dcs_0 != dcs_1:\n",
    "        num_comflict += 1\n",
    "    else:\n",
    "        num_consist += 1\n",
    "print(f\"> Decision conflict: {num_comflict}\")\n",
    "print(f\"> Decision consist: {num_consist}\")\n",
    "pprint(ces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999abf18",
   "metadata": {},
   "source": [
    "### all ratings distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581ba9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all decisions\n",
    "_cmd = \"SELECT rating_1_avg FROM submissions WHERE withdraw == 0;\"\n",
    "db.cursor.execute(_cmd)\n",
    "data = db.cursor.fetchall()\n",
    "rating_avgs = np.array(data)\n",
    "print(\"> Total submissions: {}\".format(len(data)))\n",
    "print(f\"    Average ratings: {rating_avgs.mean():.2f}\")\n",
    "print(f\"    Max ratings: {rating_avgs.max():.2f}\")\n",
    "print(f\"    Min ratings: {rating_avgs.min():.2f}\")\n",
    "\n",
    "# reject\n",
    "_cmd = \"SELECT rating_1_avg FROM submissions WHERE withdraw == 1;\"\n",
    "db.cursor.execute(_cmd)\n",
    "data = db.cursor.fetchall()\n",
    "reject_avgs = np.array(data)\n",
    "print(\"> Reject submissions: {}\".format(reject_avgs.shape[0]))\n",
    "print(f\"    Average ratings: {reject_avgs.mean():.2f}\")\n",
    "print(f\"    Max ratings: {reject_avgs.max():.2f}\")\n",
    "print(f\"    Min ratings: {reject_avgs.min():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d18fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.3\n",
    "fig = plt.figure(figsize=[16, 6])\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_facecolor((0.898, 0.925, 0.965, 0.5))\n",
    "ax.spines['left'].set_color('w')\n",
    "ax.spines['bottom'].set_color('w')\n",
    "ax.spines['right'].set_color('w')\n",
    "ax.spines['top'].set_color('w')\n",
    "\n",
    "_min, _max = rating_avgs.min(), rating_avgs.max()\n",
    "hist, bin_edges = np.histogram(rating_avgs, bins=20, range=(_min, _max))\n",
    "\n",
    "# all\n",
    "ax.bar(np.linspace(_min, _max, len(hist)), hist, width=width, alpha=0.95, \n",
    "       color='#789BFF', capsize=4, label='-')\n",
    "\n",
    "# reject\n",
    "hist_reject, _ = np.histogram(reject_avgs, bins=20, range=(_min, _max))\n",
    "ax.bar(np.linspace(_min, _max, len(hist)), hist_reject, width=width, alpha=0.95, \n",
    "       color='#ffccbd', capsize=4, label='Withdraw')\n",
    "\n",
    "for i, v in zip(np.linspace(_min, _max, len(hist)), hist):\n",
    "    ax.text(i - 0.15 if v >= 100 else i - 0.1, v + 10, str(v), color='#1f59ff', fontsize=16)\n",
    "\n",
    "ax.text(1, 300, f\"Average rating: {rating_avgs.mean():.1f}\", color='#1f59ff', fontsize=16)\n",
    "plt.ylim(0, 550)\n",
    "plt.xticks(ticks=np.linspace(_min, _max, len(hist)), rotation=40, labels=[f\"{d:.1f}\" for d in np.linspace(_min, _max, len(hist))])\n",
    "ax.set_ylabel(r\"# submissions\", fontsize=14)\n",
    "ax.set_xlabel(\"Rating\", fontsize=14)\n",
    "ax.set_axisbelow(True)\n",
    "ax.grid()\n",
    "ax.legend(loc=1, fontsize=16)\n",
    "plt.savefig('images/stats_bar_1116.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc2868",
   "metadata": {
    "id": "2cbc2868"
   },
   "source": [
    "### write consistency experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f885a0",
   "metadata": {
    "id": "e3f885a0"
   },
   "outputs": [],
   "source": [
    "check = '&#10004;'\n",
    "maps = {\n",
    "    'Oral': 'a',\n",
    "    'Spotlight': 'b',\n",
    "    'Poster': 'c',\n",
    "    'Reject': 'd'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248fd137",
   "metadata": {
    "id": "248fd137"
   },
   "outputs": [],
   "source": [
    "_cmd = \"SELECT * FROM submissions WHERE num_decision == 2 \" \\\n",
    "       \"ORDER BY CASE final_decision WHEN 'Accept (oral)' \" \\\n",
    "       \"THEN 'a' WHEN 'Accept (Spotlight)' THEN 'b' WHEN 'Accept (Poster)' \" \\\n",
    "       \"THEN 'c' WHEN 'Reject' THEN 'd' END, title DESC;\"\n",
    "db.cursor.execute(_cmd)\n",
    "data = db.cursor.fetchall()\n",
    "\n",
    "# read template \n",
    "with open('neurips2021_consistency_experiments_template.html', 'r') as f:\n",
    "    html_temp = f.readlines()\n",
    "# find insert index\n",
    "idx = html_temp.index('    <!-- start here -->\\n') + 1\n",
    "\n",
    "# write data\n",
    "for i in trange(len(data)):\n",
    "    _data = data[i]\n",
    "    final_d = _data[6].split(' ')[-1].strip('()')\n",
    "    now_d = _data[7].split(' ')[-1].strip('()')\n",
    "    _str = f\"<tr><td>{i + 1}</td><td class='td-left'><a href='{_data[1]}'> {_data[2]}</a></td>\" \\\n",
    "           f\"<td>{_data[9]:.2f}</td><td>{_data[10]:.2f}</td><td data-sort='{_data[8]}'>{_data[11]}</td>\" \\\n",
    "           f\"<td class='{final_d.lower()}' data-sort='{maps[final_d]}'>{final_d}</td>\" \\\n",
    "           f\"<td class='{now_d.lower()}' data-sort='{maps[now_d]}'>{now_d}</td>\" \\\n",
    "           f\"<td class='th-rank'>{check}</td></tr>\\n\"\n",
    "    html_temp.insert(idx + i, _str)\n",
    "\n",
    "with open('neurips2021_consistency_experiments.html' ,'w') as f:\n",
    "    f.write(\"\".join(html_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab7f63c",
   "metadata": {
    "id": "4ab7f63c"
   },
   "source": [
    "### write all submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31242d",
   "metadata": {
    "id": "5d31242d"
   },
   "outputs": [],
   "source": [
    "_cmd = \"SELECT * FROM submissions WHERE withdraw == 0 ORDER BY rating_1_avg DESC;\"\n",
    "db.cursor.execute(_cmd)\n",
    "data = db.cursor.fetchall()\n",
    "\n",
    "# read template \n",
    "with open('iclr2022_submissions_template.html', 'r') as f:\n",
    "    html_temp = f.readlines()\n",
    "# find insert index\n",
    "idx = html_temp.index('    <!-- start here -->\\n') + 1\n",
    "\n",
    "# write data\n",
    "for i in trange(len(data)):\n",
    "    _data = data[i]\n",
    "    _str = f\"<tr><td>{i + 1}</td><td class='td-left'><a href='{_data[1]}'> {_data[2]}</a></td>\" \\\n",
    "           f\"<td>{_data[5]:.2f}</td><td>{_data[9]:.2f}</td>\" \\\n",
    "           f\"<td data-sort='{(5.0 + _data[9] - _data[5]):.2f}'>{(_data[9]-_data[5]):.2f}</td>\" \\\n",
    "           f\"<td data-sort='{_data[8]}'>\" \\\n",
    "           f\"<table class='sub-table'>\" \\\n",
    "           f\"<tr><td class='r1'>{', '.join([str(int(float(_d))) for _d in _data[7].split(', ')])}</td>\" \\\n",
    "           f\"</tr><tr><td class='r2'>{_data[11]}</td></tr>\" \\\n",
    "           f\"</table></td><td></td>\" \\\n",
    "           f\"</tr>\\n\"\n",
    "    html_temp.insert(idx + i, _str)\n",
    "\n",
    "with open('iclr2022_submissions.html' ,'w') as f:\n",
    "    f.write(\"\".join(html_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca6f1e",
   "metadata": {
    "id": "b4ca6f1e"
   },
   "outputs": [],
   "source": [
    "db.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "plot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
